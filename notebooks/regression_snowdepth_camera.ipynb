{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocational-brake",
   "metadata": {},
   "source": [
    "# Regression model for snow depth in time lapse images\n",
    "\n",
    "SnowEx Hackweek 2021 \n",
    "\n",
    "*#cam_learning*\n",
    "\n",
    "__Contributors:__ Marianne Cowherd, Danny Hogan, Katie Breen, Ching-ping Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-pound",
   "metadata": {},
   "source": [
    "### __Objectives:__\n",
    "\n",
    "- Train a regression model for extracting snow depth from time-lapse imagery using supervised learning\n",
    "- Evaluate model for accuracy \n",
    "- Test potential improvemnts (i.e. cropping images) and suggest ideas for next steps\n",
    "- Learn ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-gambling",
   "metadata": {},
   "source": [
    "### __Motivations:__\n",
    "\n",
    "- 2020 SnowEx time-lapse imagery was labeled for snow-depth, but the process was time-consuming. \n",
    "- Automated methods exist using color thresholding and the Hough Transform, but background pixels add uncertainty.\n",
    "- Computer vision may be able to detect the pole without including the background noise, and identify the snow depth information \n",
    "- 2017 SnowEx time-lapse has not been labeled, and a working ML model could be applied on these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "european-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert moving video of all the camera images and snow depths underneath (Katie will add once she gets the code from Cassie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-lobby",
   "metadata": {},
   "source": [
    "### __Methods__\n",
    "\n",
    "We will use the 2020 SnowEx timelapse from one camera (W1A) as our predictor and the corresponding snow depth measurements in the SnowEx SQL database as the response, to build a supervised model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-password",
   "metadata": {},
   "source": [
    "__1) Load packages for image and data table pre-processing, model development, and model evaluation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "oriental-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /srv/conda/envs/notebook/lib/python3.8/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /srv/conda/envs/notebook/lib/python3.8/site-packages (from opencv-python-headless) (1.21.0)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this part of the tutorial uses additional libraries not in the default snowex jupyterhub\n",
    "# mamba is a python package management alternative to conda and pip https://github.com/mamba-org/mamba\n",
    "!mamba install -y -q tensorflow\n",
    "!pip install opencv-python-headless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "qualified-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Load packages for machine learning\n",
    "import tensorflow as tf  # end-to-end open source platform for machine learning\n",
    "\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "# keras is python and uses tensorflow in the backend\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "#### Packages for image processing and computer vision \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "### Packages for processing snow depth values using the SnowEx SQL database \n",
    "from snowexsql.db import get_table_attributes\n",
    "\n",
    "import snowexsql.db\n",
    "from snowexsql.data import PointData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "# Import the function to get connect to the db\n",
    "from snowexsql.db import get_db\n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-justice",
   "metadata": {},
   "source": [
    "__2. After loading the packages, we will load in the images from the Amazon Web Services S3. We will focus on one camera, W1A.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "modern-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync --no-progress s3://snowex-data/tutorial-data/camera-trap/ /tmp/camera-trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "verified-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the images \n",
    "files = os.listdir('/tmp/camera-trap/W1A')\n",
    "files =  ['/tmp/camera-trap/W1A/' + str(f) for f in files]\n",
    "\n",
    "df = pd.DataFrame([],\n",
    "                   columns=['date','photo_id','time','datetime','depth'])\n",
    "\n",
    "for i in range(0,len(files)): \n",
    "    \n",
    "    img = Image.open(files[i])\n",
    "    exif = { ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS }\n",
    "    exif['DateTime'] = datetime.strptime(exif['DateTime'],'%Y:%m:%d %H:%M:%S')\n",
    "    df.loc[i]= [exif['DateTime'].date(),\n",
    "                       files[i],\n",
    "                       exif['DateTime'].time(),exif['DateTime'],np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-purple",
   "metadata": {},
   "source": [
    "__3. Read in the images using cv2's imread function, then downscale the images to 200 x 200 pixels. 'pixels' is a list of all the images represented as an RGB array.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varying-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 200, 200, 3)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pixels_open.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-462866ae2c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#print(pixels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pixels_open.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pixels_open.npy'"
     ]
    }
   ],
   "source": [
    "pixels = []      \n",
    "for i in range(0, len(df)):\n",
    "    # img = cv2.imread(str(path)+\"/\"+str(img))\n",
    "    # src = Image.open(str(path)+\"/\"+str(img))\n",
    "    path = df['photo_id'][i]\n",
    "    src = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    #calculate the 50 percent of original dimensions\n",
    "    width =200 # int(src.shape[1] * scale_percent / 100)\n",
    "    height = 200 # int(src.shape[0] * scale_percent / 100)\n",
    "    # dsize\n",
    "    dsize = (width, height)\n",
    "    # resize image\n",
    "    output = cv2.resize(src, dsize)\n",
    "    cv2.imwrite('tmp.jpg',output) \n",
    "    # img1 = img.save('tmp', format='JPEG',dpi=(50,50))\n",
    "    img2 = cv2.imread('tmp.jpg')\n",
    "    img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
    "    pixels.append(np.array(img2))\n",
    "\n",
    "pixels = np.array(pixels)\n",
    "print(pixels.shape) \n",
    "#print(pixels)\n",
    "pixels=np.load('pixels_open.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-pattern",
   "metadata": {},
   "source": [
    "__4. Pull the snow depth values from the SnowEx SQL database__\n",
    "\n",
    "In this case, we pulled all the data from the snow depth data from camera W1A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "current-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-eaee364b886d>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['depth'][i] = df_open['value'][idx]\n"
     ]
    }
   ],
   "source": [
    "# Use the function to see what columns are available to use. \n",
    "db_columns = get_table_attributes(PointData)\n",
    "\n",
    "# Print out the results nicely\n",
    "# print(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(db_columns)))\n",
    "\n",
    "# Grab the open site data from the db\n",
    "open_site = 'W1A'\n",
    "qry = session.query(PointData).filter(PointData.equipment.contains(open_site))\n",
    "df_open = query_to_geopandas(qry,engine)\n",
    "\n",
    "# Matach the time from the images to the depth in the database\n",
    "df = pd.DataFrame([],\n",
    "                   columns=['date','photo_id','time','datetime','depth'])\n",
    "for i in range(0,len(files)): \n",
    "    \n",
    "    img = Image.open(files[i])\n",
    "    exif = { ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS }\n",
    "    exif['DateTime'] = datetime.strptime(exif['DateTime'],'%Y:%m:%d %H:%M:%S')\n",
    "    df.loc[i]= [exif['DateTime'].date(),\n",
    "                       files[i],\n",
    "                       exif['DateTime'].time(),exif['DateTime'],np.nan]\n",
    "    \n",
    "df_open['datetime'] = [datetime.combine(df_open['date'][i],df_open['time'][i]).replace(tzinfo=None) for i in range(len(df_open))]\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pivot = df['datetime'][i]\n",
    "    items = df_open['datetime']\n",
    "    tmp = np.where(items==pivot)[0]\n",
    "    if len(np.where(items==pivot)[0])>0:\n",
    "        idx = tmp[0]\n",
    "        df['depth'][i] = df_open['value'][idx]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cutting-constant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['depth']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "applicable-opening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9834726d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['datetime'],df['depth'],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-intermediate",
   "metadata": {},
   "source": [
    "__5. We will do the same as before but this time with cropped images. We will compare our results between the full images and the cropped images.__\n",
    "\n",
    "We will collapse the code to save space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aerial-static",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/cropped/W1A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7cea6f775922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcropped_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/cropped/W1A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcropped_files\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'/data/cropped/W1A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_cropped = pd.DataFrame([],\n\u001b[1;32m      5\u001b[0m                    columns=['date','photo_id','time','datetime','depth'])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/cropped/W1A'"
     ]
    }
   ],
   "source": [
    "cropped_files = os.listdir('/data/cropped/W1A')\n",
    "cropped_files =  ['/data/cropped/W1A' + str(f) for f in files]\n",
    "\n",
    "df_cropped = pd.DataFrame([],\n",
    "                   columns=['date','photo_id','time','datetime','depth'])\n",
    "for i in range(0,len(cropped_files)): \n",
    "    \n",
    "    cropped_img = Image.open(cropped_files[i])\n",
    "    exif = { ExifTags.TAGS[k]: v for k, v in cropped_img._getexif().items() if k in ExifTags.TAGS }\n",
    "    exif['DateTime'] = datetime.strptime(exif['DateTime'],'%Y:%m:%d %H:%M:%S')\n",
    "    df_cropped.loc[i]= [exif['DateTime'].date(),\n",
    "                       cropped_files[i],\n",
    "                       exif['DateTime'].time(),exif['DateTime'],np.nan]\n",
    "for i in range(len(df_cropped)):\n",
    "    pivot = df_cropped['datetime'][i]\n",
    "    items = df_open['datetime']\n",
    "    tmp = np.where(items==pivot)[0]\n",
    "    if len(np.where(items==pivot)[0])>0:\n",
    "        idx = tmp[0]\n",
    "        df_cropped['depth'][i] = df_open['value'][idx]\n",
    "\n",
    "pixels_cropped = []      \n",
    "for i in range(0, len(df_cropped)):\n",
    "    # img = cv2.imread(str(path)+\"/\"+str(img))\n",
    "    # src = Image.open(str(path)+\"/\"+str(img))\n",
    "    path = df_cropped['photo_id'][i]\n",
    "    src = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    #calculate the 50 percent of original dimensions\n",
    "    width =200 # int(src.shape[1] * scale_percent / 100)\n",
    "    height = 200 # int(src.shape[0] * scale_percent / 100)\n",
    "    # dsize\n",
    "    dsize = (width, height)\n",
    "    # resize image\n",
    "    output = cv2.resize(src, dsize)\n",
    "    cv2.imwrite('tmp.jpg',output) \n",
    "    # img1 = img.save('tmp', format='JPEG',dpi=(50,50))\n",
    "    cropped_img2 = cv2.imread('tmp.jpg')\n",
    "    cropped_img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
    "    pixels_cropped.append(np.array(cropped_img2))\n",
    "\n",
    "pixels_cropped = np.array(pixels_cropped)\n",
    "pixels_cropped =np.load('pixels_cropped_open.npy')\n",
    "\n",
    "# Use the function to see what columns are available to use. \n",
    "db_columns = get_table_attributes(PointData)\n",
    "\n",
    "# Print out the results nicely\n",
    "# print(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(db_columns)))\n",
    "\n",
    "# Grab the open site data from the db\n",
    "open_site = 'W1A'\n",
    "qry = session.query(PointData).filter(PointData.equipment.contains(open_site))\n",
    "df_open = query_to_geopandas(qry,engine)\n",
    "\n",
    "# Matach the time from the images to the depth in the database\n",
    "df_cropped = pd.DataFrame([],\n",
    "                   columns=['date','photo_id','time','datetime','depth'])\n",
    "for i in range(0,len(files)): \n",
    "    \n",
    "    img = Image.open(files[i])\n",
    "    exif = { ExifTags.TAGS[k]: v for k, v in img._getexif().items() if k in ExifTags.TAGS }\n",
    "    exif['DateTime'] = datetime.strptime(exif['DateTime'],'%Y:%m:%d %H:%M:%S')\n",
    "    df_cropped.loc[i]= [exif['DateTime'].date(),\n",
    "                       files[i],\n",
    "                       exif['DateTime'].time(),exif['DateTime'],np.nan]\n",
    "    \n",
    "df_open['datetime'] = [datetime.combine(df_open['date'][i],df_open['time'][i]).replace(tzinfo=None) for i in range(len(df_open))]\n",
    "\n",
    "\n",
    "for i in range(len(df_cropped)):\n",
    "    pivot = df_cropped['datetime'][i]\n",
    "    items = df_open['datetime']\n",
    "    tmp = np.where(items==pivot)[0]\n",
    "    if len(np.where(items==pivot)[0])>0:\n",
    "        idx = tmp[0]\n",
    "        df_cropped['depth'][i] = df_open['value'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-envelope",
   "metadata": {},
   "source": [
    "__6. Flattening pixels data in a table.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "rough-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pixels.reshape((659,-1))\n",
    "dataset = np.concatenate((dataset, np.array(df['depth']).reshape((659,1))),axis=1)\n",
    "dataset = pd.DataFrame(dataset)\n",
    "np.save('dataset_open.npy', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-connection",
   "metadata": {},
   "source": [
    "__7. Machine Learning Linear Regression.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "departmental-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-c35e5314d888>:2: RuntimeWarning: invalid value encountered in greater\n",
      "  dataset=dataset[dataset[:,-1]>0]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load('dataset_open.npy',allow_pickle=True)\n",
    "dataset = dataset[dataset[:,-1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "racial-stick",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-86a5788597f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "executive-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:400: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:401: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_dataset)\n",
    "scaled_test = scaler.transform(test_dataset) ## fit_transform != transform. \n",
    "                                             ## transform uses the parameters of fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "neutral-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = scaled_train[:, :-1], scaled_train[:, -1]\n",
    "test_X, test_y = scaled_test[:, :-1], scaled_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "danish-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0) ## For reproducible results\n",
    "linear_regression = tf.keras.models.Sequential() # Specify layers in their sequential order\n",
    "# inputs are 4 dimensions (4 dimensions = 4 features)\n",
    "# Dense = Fully Connected.  \n",
    "linear_regression.add(tf.keras.layers.Dense(1, activation=None ,input_shape=(train_X.shape[1],)))\n",
    "# Output layer has no activation with just 1 node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "operating-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "linear_regression.compile(optimizer = opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "induced-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 120001    \n",
      "=================================================================\n",
      "Total params: 120,001\n",
      "Trainable params: 120,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(linear_regression.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "alpha-creature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1min 7s, total: 2min 11s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NOTE: can changed from epochs=150 to run faster, change to verbose=1 for per-epoch output\n",
    "history =linear_regression.fit(train_X, train_y, epochs=100, validation_split = 0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "refined-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
